{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HR/LR Synthetic Image Generation  \n",
        "\n"
      ],
      "metadata": {
        "id": "LvRbMoEBCOC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notebook**: Creates paired HR (256px) and LR (64px) patches with:  \n",
        "- Blur degradation  \n",
        "- Poisson + sensor noise  \n",
        "- Bicubic/bilinear downsampling  \n",
        "<br>"
      ],
      "metadata": {
        "id": "XtpVdWjNCPKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1 Import dependencies"
      ],
      "metadata": {
        "id": "ZLaHhV7hwepY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOe3Meh-mb2q"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageFilter\n",
        "from google.colab import drive, files\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import io\n",
        "import zipfile\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd5TAqzwm0o9"
      },
      "source": [
        "#2 Upload image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bahMeeTVCqAP",
        "outputId": "f697cd23-488d-4f18-8c3c-8700743ac90b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FZB-5IhnK_V"
      },
      "source": [
        "#3 Create patches of 256 by 256 pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbHYPP3Am6SW"
      },
      "outputs": [],
      "source": [
        "# Create output folder\n",
        "output_dir = \"patches_256\"\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_patches(image, width, height, output_dir, prefix):\n",
        "    \"\"\"Extract square patches from an image and save as PNG files.\n",
        "\n",
        "    Args:\n",
        "        image: PIL.Image - Source image to split into patches\n",
        "        width: int - Image width in pixels (must match actual image width)\n",
        "        height: int - Image height in pixels (must match actual image height)\n",
        "        output_dir: str - Directory to save patches (e.g. '/content/patches')\n",
        "        prefix: str - Prefix for filenames (e.g. 'Nepal')\n",
        "\n",
        "    Output:\n",
        "        Saves files: {output_dir}/{prefix}_patch_N.png (N starts at 0)\n",
        "        Prints total number of patches saved\n",
        "\n",
        "    How it works:\n",
        "        - Slides a 256x256 window across the image with no overlap\n",
        "        - Saves each patch as separate PNG\n",
        "        - Uses global 'prefix' for filenames (e.g. 'Nepal_patch_0.png')\n",
        "    \"\"\"\n",
        "    patch_size=256\n",
        "    patch_id = 0\n",
        "\n",
        "    for top in range(0, height - patch_size + 1, patch_size):\n",
        "        for left in range(0, width - patch_size + 1, patch_size):\n",
        "            image.crop((left, top, left + patch_size, top + patch_size)) \\\n",
        "               .save(f\"{output_dir}/{prefix}_patch_{patch_id}.png\")\n",
        "            patch_id += 1\n",
        "\n",
        "    print(f\"Saved {patch_id} patches (using pre-calculated size {width}x{height})\")"
      ],
      "metadata": {
        "id": "KBverOzbyDc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = \"/content/drive/MyDrive/Final_project/OriginalImages/SatelliteImages\"\n",
        "output_dir = \"/content/patches_256\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Get all PNG files in the directory\n",
        "png_files = [f for f in os.listdir(input_dir) if f.lower().endswith('.png')]\n",
        "\n",
        "# Process each image\n",
        "for png_file in png_files:\n",
        "    img_path = os.path.join(input_dir, png_file)\n",
        "    print(f\"\\nProcessing image: {img_path}\")\n",
        "    prefix = os.path.splitext(png_file)[0]\n",
        "    # Load image and print dimensions for verification\n",
        "    image = Image.open(img_path)\n",
        "    width, height = image.size\n",
        "    print(f\"Image size: {width} x {height}\")\n",
        "\n",
        "    # Call patch extraction function\n",
        "    extract_patches(image, width, height, output_dir, prefix)\n",
        "\n",
        "    image.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrvOeAIW5OZq",
        "outputId": "00be6a36-c519-470d-c0f1-4a7d605fc58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing image: /content/drive/MyDrive/Final_project/OriginalImages/SatelliteImages/usefordemo.png\n",
            "Image size: 345 x 547\n",
            "Saved 2 patches (using pre-calculated size 345x547)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbqwrTgYuA3k"
      },
      "source": [
        "#4 Create HR images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z43gitTuGYz"
      },
      "source": [
        "##4.1 Check lapalcian pyramid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_high_quality(patch):\n",
        "    \"\"\"Determine if an image patch has sufficient texture and sharpness.\n",
        "\n",
        "    Args:\n",
        "        patch: PIL.Image - Input image patch to evaluate\n",
        "\n",
        "    Returns:\n",
        "        bool: True if patch passes both quality checks:\n",
        "            - Standard deviation >= 25 (contrast/texture)\n",
        "            - Average Laplacian variance across pyramid levels >= 80\n",
        "\n",
        "    How it works:\n",
        "        1. Converts patch to numpy array\n",
        "        2. Rejects if pixel intensity std dev < 25 (flat regions)\n",
        "        3. Rejects if average Laplacian pyramid variance < 80 (blurry/soft edges across scales)\n",
        "    \"\"\"\n",
        "    patch_np = np.array(patch)\n",
        "\n",
        "    # Standard deviation check (contrast/texture)\n",
        "    sd = np.std(patch_np)\n",
        "    if sd < 25:\n",
        "        return False\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(patch_np, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Build Laplacian pyramid with 3 levels to check\n",
        "    max_levels = 3\n",
        "    pyramid_vars = []\n",
        "\n",
        "    current = gray.copy()\n",
        "    for _ in range(max_levels):\n",
        "        laplacian = cv2.Laplacian(current, cv2.CV_64F)\n",
        "        pyramid_vars.append(np.var(laplacian))\n",
        "        current = cv2.pyrDown(current)  # downsample for next level\n",
        "\n",
        "    # Take average sharpness measure across levels\n",
        "    avg_var = np.mean(pyramid_vars)\n",
        "\n",
        "    if avg_var < 80:\n",
        "        return False\n",
        "\n",
        "    return True\n"
      ],
      "metadata": {
        "id": "zImHErAqgMv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWGWi4d0uAK9"
      },
      "outputs": [],
      "source": [
        "def rename_low_quality_patches(output_dir):\n",
        "    \"\"\"Renames low-quality image patches by adding 'low_quality_' prefix.\n",
        "\n",
        "    Args:\n",
        "        output_dir: Directory containing the patch PNG files to check\n",
        "\n",
        "    Output:\n",
        "        Renames PNG files flagged as low qaulity\n",
        "        Prints renaming actions to console\n",
        "\n",
        "    How it works:\n",
        "        1. Finds all files matching '{prefix}_patch_*.png'\n",
        "        2. Checks each with is_high_quality()\n",
        "        3. Renames and logs low quality patches\n",
        "    \"\"\"\n",
        "    for filename in os.listdir(output_dir):\n",
        "        if filename.endswith(\".png\"):\n",
        "            filepath = os.path.join(output_dir, filename)\n",
        "            patch = Image.open(filepath)\n",
        "\n",
        "            if not is_high_quality(patch):\n",
        "                new_name = \"low_quality_\" + filename\n",
        "                new_path = os.path.join(output_dir, new_name)\n",
        "                os.rename(filepath, new_path)\n",
        "                print(f\"Renamed {filename} to {new_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC955LNQvCNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc9a7ef-7bec-4412-e81d-6f1a11f78f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Renamed usefordemo_patch_1.png to low_quality_usefordemo_patch_1.png\n"
          ]
        }
      ],
      "source": [
        "rename_low_quality_patches(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoavvUxXvq-N"
      },
      "source": [
        "##4.2 Sharpen HR images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHmvncHUvL06"
      },
      "outputs": [],
      "source": [
        "sharpened_dir = 'hr_patches_256'\n",
        "os.makedirs(sharpened_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Orjpi51HvwpA",
        "outputId": "9d2a1440-171e-4053-ad0e-8645a4230505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sharpened 1 images. Saved to hr_patches_256/\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# PATCH SHARPENING CONFIGURATION\n",
        "# =============================================================================\n",
        "radius = 2      # Smaller = finer details (1.0-2.0)\n",
        "percent = 50    # Strength (50-100)\n",
        "threshold = 5   # Only sharpen areas with contrast above this (0-10)\n",
        "\n",
        "# =============================================================================\n",
        "# SHARPENING PROCESS\n",
        "# =============================================================================\n",
        "\"\"\"\n",
        "Process:\n",
        "    1. Scans output_dir for patch images\n",
        "    2. Skips already sharpened/low-quality files\n",
        "    3. Applies unsharp mask with current settings\n",
        "    4. Saves sharpened versions to sharpened_dir\n",
        "\n",
        "Output:\n",
        "    - Creates sharp_*.png copies in sharpened_dir\n",
        "    - Prints success count and error messages\n",
        "    - Preserves original files\n",
        "\"\"\"\n",
        "processed_count = 0\n",
        "\n",
        "for patch_path in os.listdir(output_dir):\n",
        "\n",
        "    full_path = os.path.join(output_dir, patch_path)\n",
        "    # Skip directories like .ipynb_checkpoints\n",
        "    if os.path.isdir(full_path):\n",
        "        continue\n",
        "\n",
        "    # Skip files that are already sharpened or marked as low quality\n",
        "    if patch_path.startswith(('sharp_', 'low_quality_')):\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        with Image.open(os.path.join(output_dir, patch_path)) as img:\n",
        "            # Apply sharpening\n",
        "            sharp = img.filter(\n",
        "                ImageFilter.UnsharpMask(\n",
        "                    radius=radius,\n",
        "                    percent=percent,\n",
        "                    threshold=threshold\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # Save with sharp_ prefix\n",
        "            sharp.save(os.path.join(sharpened_dir, patch_path))\n",
        "            processed_count += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {patch_path}\")\n",
        "\n",
        "print(f\"Sharpened {processed_count} images. Saved to {sharpened_dir}/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc42AmRKz7ih"
      },
      "source": [
        "#5 Create LR images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB6dhRvH0Ux3"
      },
      "source": [
        "##5.1 Image blur"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_dir = \"/content/drive/MyDrive/Final_project/OriginalImages/SatelliteImages\""
      ],
      "metadata": {
        "id": "pZxNes7hyxDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r3NyhbSxgDu",
        "outputId": "0671c721-b51f-4960-f12c-acea3fef9d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random degradation parameters: {'motion_length': np.int64(3), 'motion_angle': np.int64(45), 'defocus_radius': np.int64(3), 'gaussian_sigma': np.float64(0.5), 'resampling_type': np.str_('bilinear')}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# =============================================================================\n",
        "# DEGRADATION PARAMETER OPTIONS\n",
        "# =============================================================================\n",
        "\"\"\"\n",
        "- motion_length: Blur distance in pixels (3-7)\n",
        "- motion_angle: Blur direction in degrees (45 degrees increments)\n",
        "- defocus_radius: Out-of-focus blur strength (3-5)\n",
        "- gaussian_sigma: General blur intensity (0.5-1.2)\n",
        "- resampling_type: Downscaling method (bicubic or bilinear)\n",
        "\"\"\"\n",
        "param_ranges = {\n",
        "    'motion_length': [3, 7],\n",
        "    'motion_angle': [45, 90, 135, 180],\n",
        "    'defocus_radius': [3, 5],\n",
        "    'gaussian_sigma': [0.5, 1.2],\n",
        "    'resampling_type': ['bicubic', 'bilinear']\n",
        "}\n",
        "\n",
        "def get_random_degradation():\n",
        "    \"\"\"Generates random image degradation parameters.\n",
        "\n",
        "    Returns:\n",
        "        dict: Randomly selected values for all parameters in param_ranges\n",
        "    \"\"\"\n",
        "    return {key: np.random.choice(values) for key, values in param_ranges.items()}\n",
        "\n",
        "# Random param values\n",
        "random_params = get_random_degradation()\n",
        "print(\"Random degradation parameters:\", random_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8gVpv8R1BoV"
      },
      "outputs": [],
      "source": [
        "# Define blur degradation functions\n",
        "def apply_motion_blur(img, L, F):\n",
        "    \"\"\"Applies directional motion blur to an image.\n",
        "\n",
        "    Args:\n",
        "        img: Input image (numpy array)\n",
        "        L: Length of motion blur\n",
        "        F: Angle of motion in degrees\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Image with motion blur applied\n",
        "\n",
        "    How it works:\n",
        "        1. Creates horizontal motion kernel\n",
        "        2. Rotates kernel to specified angle\n",
        "        3. Applies using 2D convolution\n",
        "    \"\"\"\n",
        "    kernel = np.zeros((L, L))\n",
        "    center = L // 2\n",
        "    kernel[center, :] = np.ones(L) / L\n",
        "    M = cv2.getRotationMatrix2D((float(center), float(center)), F, 1)\n",
        "    kernel = cv2.warpAffine(kernel, M, (L, L))\n",
        "    return cv2.filter2D(img, -1, kernel)\n",
        "\n",
        "def apply_defocus_blur(img, r):\n",
        "    \"\"\"Applies circular defocus blur to simulate out-of-focus effect.\n",
        "\n",
        "    Args:\n",
        "        img: Input image (numpy array)\n",
        "        r: Radius of blur circle (pixels)\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Image with defocus blur\n",
        "\n",
        "    How it works:\n",
        "        1. Creates circular kernel\n",
        "        2. Normalizes kernel values\n",
        "        3. Applies using 2D convolution\n",
        "    \"\"\"\n",
        "    kernel = np.zeros((2*r+1, 2*r+1))\n",
        "    cv2.circle(kernel, (r, r), r, 1, -1)\n",
        "    kernel /= kernel.sum()\n",
        "    return cv2.filter2D(img, -1, kernel)\n",
        "\n",
        "def apply_gaussian_blur(img, sigma):\n",
        "    \"\"\"Applies Gaussian blur for general smoothing.\n",
        "\n",
        "    Args:\n",
        "        img: Input image (numpy array)\n",
        "        sigma: Standard deviation of Gaussian kernel\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Blurred image\n",
        "\n",
        "    How it works:\n",
        "        Uses fixed 25x25 kernel with specified sigma\n",
        "        (Larger sigma = more blur)\n",
        "    \"\"\"\n",
        "    kernel_size = 25\n",
        "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), sigmaX=sigma)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UQwp4se1Jb9"
      },
      "outputs": [],
      "source": [
        "# Applies degradations using random params generated previously\n",
        "def process_image_cumulative(img):\n",
        "    \"\"\"Applies multiple degradations to an image using predefined random parameters\n",
        "    in a random order.\n",
        "\n",
        "    Args:\n",
        "        img (np.ndarray): Input image loaded via OpenCV in BGR format.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Degraded image with combined effects\n",
        "    \"\"\"\n",
        "    degraded = img.copy()\n",
        "\n",
        "    # Define the blur operations as lambdas so that their order of execution can be shuffled\n",
        "    ops = [\n",
        "        lambda im: apply_motion_blur(im, random_params['motion_length'], random_params['motion_angle']),\n",
        "        lambda im: apply_defocus_blur(im, random_params['defocus_radius']),\n",
        "        lambda im: apply_gaussian_blur(im, random_params['gaussian_sigma'])\n",
        "    ]\n",
        "\n",
        "    # Shuffle the operations\n",
        "    random.shuffle(ops)\n",
        "\n",
        "    # Apply in random order\n",
        "    for op in ops:\n",
        "        degraded = op(degraded)\n",
        "\n",
        "    print(f\"Applied from random_params: \"\n",
        "          f\"L={random_params['motion_length']}, \"\n",
        "          f\"F={random_params['motion_angle']}°, \"\n",
        "          f\"r={random_params['defocus_radius']}, \"\n",
        "          f\"σ={random_params['gaussian_sigma']:.1f}\")\n",
        "\n",
        "    return degraded"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qwcDQvi5GAkM",
        "outputId": "848fa905-22db-4fd6-fe7a-020da8205f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Final_project/OriginalImages/SatelliteImages'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqWj-ff11cR6",
        "outputId": "460697b6-bc6c-4f09-8256-e087416a6ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied from random_params: L=3, F=45°, r=3, σ=0.5\n",
            "Processed italystadiumAirbus.png\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# IMAGE BLUR PROCESSING EXECUTION\n",
        "# =============================================================================\n",
        "\"\"\"\n",
        "Process:\n",
        "    1. Loads image from specified path using OpenCV (BGR format)\n",
        "    2. Applies cumulative degradations using process_image_cumulative()\n",
        "    3. Stores result in blurred_img variable\n",
        "\n",
        "Note: Uses random_params generated earlier for degradation settings\"\"\"\n",
        "\n",
        "dst_dir = \"/content/blurred_images\"\n",
        "os.makedirs(dst_dir, exist_ok=True)\n",
        "\n",
        "for img_name in os.listdir(src_dir):\n",
        "    if img_name.lower().endswith(('.png')):\n",
        "        src = os.path.join(src_dir, img_name)\n",
        "        dst = os.path.join(dst_dir, img_name)\n",
        "\n",
        "        img = cv2.imread(src)\n",
        "        if img is not None:\n",
        "            cv2.imwrite(dst, process_image_cumulative(img))\n",
        "            print(f\"Processed {img_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI7ovpjUa6IK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c42140e6-3d3d-4139-8b30-3cdd486b0d00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nplt.imshow(cv2.cvtColor(blurred_img, cv2.COLOR_BGR2RGB))\\nplt.axis('off')\\nplt.show()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "\"\"\"\n",
        "plt.imshow(cv2.cvtColor(blurred_img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuc2tSBf6s6B"
      },
      "source": [
        "##5.2 Noise Addition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.2.1 Add poisson noise - photon noise"
      ],
      "metadata": {
        "id": "hxTC4O12jJDy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LMZXSzU5XVy"
      },
      "outputs": [],
      "source": [
        "def add_poisson_noise(image_array, scale=1.3):\n",
        "    \"\"\"Adds Poisson (shot) noise to an image, preserving brightness distribution.\n",
        "\n",
        "    Args:\n",
        "        image_array: Input image (uint8 [0,255] or float [0,1])\n",
        "        scale: Noise intensity multiplier (higher = more noise)\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Noisy image (same datatype as input)\n",
        "\n",
        "    How it works:\n",
        "        1. Normalises image to [0,1] float if needed\n",
        "        2. Scales intensity to control noise level\n",
        "        3. Applies Poisson noise (photon counting statistics)\n",
        "        4. Restores original range and dtype\n",
        "    \"\"\"\n",
        "    if image_array.dtype == np.uint8:\n",
        "        img_float = image_array.astype(np.float32) / 255.0\n",
        "    else:\n",
        "        img_float = image_array.copy()\n",
        "\n",
        "    scaled_img = img_float * scale\n",
        "\n",
        "    noisy_float = np.random.poisson(scaled_img * 255) / 255.0\n",
        "    noisy_float = noisy_float / scale\n",
        "\n",
        "    if image_array.dtype == np.uint8:\n",
        "        return np.clip(noisy_float * 255, 0, 255).astype(np.uint8)\n",
        "    else:\n",
        "        return np.clip(noisy_float, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prAoDeGvUvX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2043c619-3432-446c-dbd0-903ca46db876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed plantation.png\n",
            "Processed pittsburg.png\n",
            "Processed italystadiumAirbus.png\n"
          ]
        }
      ],
      "source": [
        "# 1 Define paths\n",
        "noisy_dir = \"/content/noisy_images\"\n",
        "os.makedirs(noisy_dir, exist_ok=True)\n",
        "\n",
        "# 2 Process each PNG\n",
        "for img_name in os.listdir(dst_dir):\n",
        "    if img_name.lower().endswith('.png'):\n",
        "        # Load image\n",
        "        img_path = os.path.join(dst_dir, img_name)\n",
        "        blurred_img = cv2.imread(img_path)\n",
        "\n",
        "        if blurred_img is not None:\n",
        "            # Add Poisson noise\n",
        "            noisy_img = add_poisson_noise(blurred_img, scale=1.0)\n",
        "\n",
        "            # Save with same name to output directory\n",
        "            cv2.imwrite(os.path.join(noisy_dir, img_name), noisy_img)\n",
        "            print(f\"Processed {img_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "plt.imshow(cv2.cvtColor(noisy_img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "QwS0Dz9RitqE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "601da67c-02db-44b7-be48-f5b71833cb6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nplt.imshow(cv2.cvtColor(noisy_img, cv2.COLOR_BGR2RGB))\\nplt.axis('off')\\nplt.show()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.2.2 Add intrumental noise - thermal and quantisation"
      ],
      "metadata": {
        "id": "spH7kSk3jO0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_instrumental_noise(noisy_img, thermal_std=2.5, quantize=True):\n",
        "    \"\"\"Adds realistic sensor noise to an image (thermal + quantization noise).\n",
        "\n",
        "    Args:\n",
        "        noisy_img: Input image array (uint8 or float)\n",
        "        thermal_std: Standard deviation of thermal noise (in 8-bit units)\n",
        "        quantize: Whether to add quantization noise (for digital sensors)\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Image with combined noise (uint8)\n",
        "\n",
        "    How it works:\n",
        "        1. Converts image to float32 for processing\n",
        "        2. Adds Gaussian thermal noise\n",
        "        3. Optionally adds uniform quantization noise (+- 0.5)\n",
        "        4. Clips to valid range and returns as uint8\n",
        "    \"\"\"\n",
        "    img_float = noisy_img.astype(np.float32)\n",
        "\n",
        "    img_float += np.random.normal(0, thermal_std, size=noisy_img.shape)\n",
        "\n",
        "    if quantize:\n",
        "        img_float += np.random.uniform(-0.5, 0.5, size=noisy_img.shape)\n",
        "\n",
        "    final_img = np.clip(img_float, 0, 255).astype(np.uint8)\n",
        "\n",
        "    return final_img"
      ],
      "metadata": {
        "id": "UAzSVo5siJTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phy_noisy_dir = \"/content/physically_noisy_image\"\n",
        "os.makedirs(phy_noisy_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "for img_name in os.listdir(noisy_dir):\n",
        "    if img_name.endswith('.png'):\n",
        "        img = cv2.imread(f\"{noisy_dir}/{img_name}\")\n",
        "        if img is not None:\n",
        "            noisy = add_poisson_noise(img, 1.0)\n",
        "            final = add_instrumental_noise(noisy)\n",
        "            cv2.imwrite(f\"{phy_noisy_dir}/{img_name}\", final)\n",
        "            print(f\"Processed {img_name}\")"
      ],
      "metadata": {
        "id": "BRMtrsGsje-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a072b47-439a-4e4d-e288-7dd9bddd2ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed plantation.png\n",
            "Processed pittsburg.png\n",
            "Processed italystadiumAirbus.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "plt.imshow(cv2.cvtColor(physically_noisy_img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2G71CcYJlHwz",
        "outputId": "8269f918-260e-4a44-9673-e46967f7f765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nplt.imshow(cv2.cvtColor(physically_noisy_img, cv2.COLOR_BGR2RGB))\\nplt.axis('off')\\nplt.show()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.3 create 256 by 256 patches"
      ],
      "metadata": {
        "id": "ETbNLQgzwi90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# LOW-RESOLUTION PATCH GENERATION\n",
        "# =============================================================================\n",
        "\"\"\"\n",
        "Process:\n",
        "    1. Creates output directory lr_patches_256 if not exist\n",
        "    2. Converts noisy BGR image to RGB format\n",
        "    3. Converts numpy array to PIL Image format\n",
        "    4. Extracts 256x256 patches using extract_patches()\n",
        "\n",
        "Output:\n",
        "    - Saves patches to lr_patches_256/\n",
        "    - Filename format: {prefix}_patch_<id>.png\n",
        "    - Prints total patch count when complete\n",
        "\"\"\"\n",
        "lr_output_dir = \"lr_patches_256\"\n",
        "os.makedirs(lr_output_dir, exist_ok=True)\n",
        "\n",
        "# Process each noisy image\n",
        "for img_name in os.listdir(phy_noisy_dir):\n",
        "    if img_name.endswith('.png'):\n",
        "        # Load image\n",
        "        img_path = os.path.join(phy_noisy_dir, img_name)\n",
        "        physically_noisy_img = cv2.imread(img_path)\n",
        "\n",
        "        if physically_noisy_img is not None:\n",
        "            # Convert to PIL format\n",
        "            physically_noisy_rgb = cv2.cvtColor(physically_noisy_img, cv2.COLOR_BGR2RGB)\n",
        "            physically_noisy_pil = Image.fromarray(physically_noisy_rgb)\n",
        "\n",
        "            # Get image dimensions\n",
        "            width, height = physically_noisy_pil.size\n",
        "\n",
        "            # Generate prefix from filename\n",
        "            prefix = os.path.splitext(img_name)[0]\n",
        "\n",
        "            # Extract and save patches\n",
        "            extract_patches(physically_noisy_pil, width, height, lr_output_dir, prefix)\n",
        "            print(f\"Processed patches for: {img_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAhoeYVcwnsX",
        "outputId": "8c3c2c73-e0e4-4a76-eccd-9c9680749427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 2 patches (using pre-calculated size 345x547)\n",
            "Processed patches for: usefordemo.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PATCH SYNCHRONIZATION (HR-LR PAIR CLEANUP)\n",
        "# =============================================================================\n",
        "\"\"\"\n",
        "Process:\n",
        "    1. Identifies all HR patches in sharpened_dir\n",
        "    2. Identifies all LR patches in lr_patches_256\n",
        "    3. Finds LR patches without matching HR patches\n",
        "    4. Deletes LR patches with no matching HR image\n",
        "\n",
        "Output:\n",
        "    - Removes inconsistent LR patches\n",
        "    - Prints names of deleted patches\n",
        "    - Reports total deletion count\n",
        "\"\"\"\n",
        "\n",
        "hr_patches = set(os.listdir(sharpened_dir))\n",
        "lr_patches = set(os.listdir(lr_output_dir))\n",
        "\n",
        "to_delete = lr_patches - hr_patches\n",
        "\n",
        "for patch_name in to_delete:\n",
        "    os.remove(os.path.join(lr_output_dir, patch_name))\n",
        "    print(f\"Deleted LR patch: {patch_name}\")\n",
        "\n",
        "print(f\"Deleted {len(to_delete)} LR patches without HR counterparts\")"
      ],
      "metadata": {
        "id": "5TfT0SFX9Qwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "462f1af9-7d40-48c1-dd35-cd05416c983c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted LR patch: usefordemo_patch_1.png\n",
            "Deleted 1 LR patches without HR counterparts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.4 Down sampling"
      ],
      "metadata": {
        "id": "8LTdMYNJ9qNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_downsampling(noisy_img, scale_factor=4):\n",
        "    \"\"\"Downsamples an image while maintaining HR-LR correspondence.\n",
        "\n",
        "      Args:\n",
        "      noisy_img: Noisy input image (BGR format)\n",
        "      scale_factor: Scaling ratio\n",
        "\n",
        "      Returns:\n",
        "      np.ndarray: Downsampled image in RGB format\n",
        "\n",
        "      How it works:\n",
        "      1. Calculates new dimensions (original // scale_factor)\n",
        "      2. Applies either bicubic or bilinear resampling\n",
        "      (based on random_params['resampling_type' ])\n",
        "      3. Converts output to RGB color space\n",
        "    \"\"\"\n",
        "    h, w = noisy_img.shape[:2]\n",
        "    new_w, new_h = w // scale_factor, h // scale_factor\n",
        "\n",
        "    # Use the resampling type from random_params\n",
        "    if random_params['resampling_type'] == 'bicubic':\n",
        "        lr_img = cv2.resize(noisy_img, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
        "    else:\n",
        "        lr_img = cv2.resize(noisy_img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    return cv2.cvtColor(lr_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "# Path to newlr dir\n",
        "output_dir = \"lr_patches_64\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Process each patch\n",
        "for patch_name in os.listdir(lr_output_dir):\n",
        "    if patch_name.endswith('.png'):\n",
        "        patch_path = os.path.join(lr_output_dir, patch_name)\n",
        "\n",
        "        img = cv2.imread(patch_path)\n",
        "        if img is not None:\n",
        "            downsampled = apply_downsampling(img)\n",
        "            save_path = os.path.join(output_dir, patch_name)\n",
        "            cv2.imwrite(save_path, cv2.cvtColor(downsampled, cv2.COLOR_RGB2BGR))\n",
        "            # print(f\"Downsampled: {patch_name}\")\n",
        "\n",
        "print(f\"All patches downsampled and saved in '{output_dir}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eYCcy1B5sn8",
        "outputId": "f8bfa283-c682-43ff-ee43-7575eae187e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All patches downsampled and saved in 'lr_patches_64'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6 Download HR and LR images"
      ],
      "metadata": {
        "id": "2Jiq4CkL_sCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PATCH ARCHIVING & DOWNLOAD\n",
        "# =============================================================================\n",
        "\"\"\"\n",
        "Final Output:\n",
        "    1. HR Patches (256px):\n",
        "       - Source: {sharpened_dir}/\n",
        "       - Archive: hr_patches_256.zip\n",
        "    2. LR Patches (64px):\n",
        "       - Source: lr_patches_64/\n",
        "       - Archive: lr_patches_64.zip\n",
        "\n",
        "Process:\n",
        "    1. Creates ZIP archives of both patch sehts\n",
        "    2. Triggers download via Colab's files.download()\n",
        "    3. Preserves directory structure in archives\n",
        "\n",
        "Note:\n",
        "  Appends new png images to existing hr_patches_256/ and lr_patches_64/\n",
        "  For downloading inference images, comment lines for hr\n",
        "\"\"\"\n",
        "!zip -r hr_patches_256.zip {sharpened_dir}\n",
        "files.download('hr_patches_256.zip')\n",
        "\n",
        "!zip -r lr_patches_64.zip {output_dir}/\n",
        "files.download('lr_patches_64.zip')"
      ],
      "metadata": {
        "id": "9YMTF0P7-K-C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "cb872873-c3b6-4aa6-9fb6-2b5f64b2bd9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: hr_patches_256/ (stored 0%)\n",
            "  adding: hr_patches_256/usefordemo_patch_0.png (deflated 0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4169ffb0-a893-4645-babb-8cb954a19131\", \"hr_patches_256.zip\", 138931)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: lr_patches_64/ (stored 0%)\n",
            "  adding: lr_patches_64/usefordemo_patch_0.png (stored 0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7f5b6cf6-21cc-4cab-a5a9-435ab44b82c0\", \"lr_patches_64.zip\", 10032)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZLaHhV7hwepY",
        "gd5TAqzwm0o9",
        "0FZB-5IhnK_V",
        "9Z43gitTuGYz",
        "uoavvUxXvq-N",
        "iB6dhRvH0Ux3",
        "hxTC4O12jJDy",
        "spH7kSk3jO0D",
        "ETbNLQgzwi90",
        "8LTdMYNJ9qNO",
        "2Jiq4CkL_sCT"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}