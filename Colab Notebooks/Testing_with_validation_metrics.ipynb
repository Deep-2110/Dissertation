{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "H-S7_uENNkNy",
        "LsHoQUSH1743",
        "U2a3JMKE1V_4",
        "2nBwedhW1jbv",
        "jx53S7Hu12Zn",
        "VYAFHFfG2h2-",
        "AOE2mLG94hfC",
        "hnprnVuU8oCG"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Readme"
      ],
      "metadata": {
        "id": "H-S7_uENNkNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ground truth and low resolution of images for test dataset should be positioned at MyDrive/Final_project/gt_test_images.zip and MyDrive/Final_project/models_test_results.zip respectively.\n",
        "<br>\n",
        "The fodler structure for both zip files are as follow:\n",
        "<pre>\n",
        "gt_test_images.zip\n",
        "    |_buildings\n",
        "    |_desert\n",
        "    |_snowregion\n",
        "    |_vegetation\n",
        "<br>\n",
        "models_test_results.zip\n",
        "    |_models_test_results\n",
        "              |_bsrgan\n",
        "                  |_FineTuned\n",
        "                  |   |_buildings\n",
        "                  |   |_desert\n",
        "                  |   |_snowregion\n",
        "                  |   |_vegetation\n",
        "                  |_NotFineTuned\n",
        "                      |_buildings\n",
        "                      |_desert\n",
        "                      |_snowregion\n",
        "                      |_vegetation\n",
        "<br> The hierarchy is same for hat, realesrgan and swinir                       "
      ],
      "metadata": {
        "id": "FVCnuaBlNl7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1 Install dependencies and import libraries"
      ],
      "metadata": {
        "id": "LsHoQUSH1743"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install basicsr -qqq"
      ],
      "metadata": {
        "id": "iRVMLuvM2F3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#basicssr contains a file degradation.py where the import library is obsolete\n",
        "#and has to be replaced\n",
        "#https://github.com/xinntao/Real-ESRGAN/issues/801\n",
        "\n",
        "file_path = \"/usr/local/lib/python3.12/dist-packages/basicsr/data/degradations.py\"\n",
        "line_to_replace = \"from torchvision.transforms.functional_tensor import rgb_to_grayscale\"\n",
        "new_line = \"from torchvision.transforms.functional import rgb_to_grayscale\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "lines = [new_line if line.strip() == line_to_replace else line for line in lines]\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    file.writelines(lines)\n",
        "\n",
        "print(f\"Replacing line '{line_to_replace}' with '{new_line}' in file {file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3ubhoC12NcO",
        "outputId": "3d35b2f0-7479-4fd6-ad4b-9da4e72084e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replacing line 'from torchvision.transforms.functional_tensor import rgb_to_grayscale' with 'from torchvision.transforms.functional import rgb_to_grayscale' in file /usr/local/lib/python3.12/dist-packages/basicsr/data/degradations.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8nAyAzd0kta"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from skimage import io, metrics, transform, color\n",
        "import basicsr\n",
        "from basicsr.metrics.niqe import calculate_niqe as bs_calculate_niqe\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy3LZh0E0m0G",
        "outputId": "754085b1-c4ba-4f77-fdbc-72557b9dc0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Calculate PSNR"
      ],
      "metadata": {
        "id": "U2a3JMKE1V_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_psnr(gt_path, test_path):\n",
        "    \"\"\"\n",
        "    Calculate PSNR between two images.\n",
        "    \"\"\"\n",
        "    # Read images\n",
        "    gt_image = io.imread(gt_path)\n",
        "    test_image = io.imread(test_path)\n",
        "\n",
        "    # Remove alpha channel if present\n",
        "    # Alpha channel represents transparency; incompatible with PSNR which is for rgb or greyscale\n",
        "    if gt_image.shape[2] == 4:\n",
        "        gt_image = gt_image[:, :, :3]\n",
        "    if test_image.shape[2] == 4:\n",
        "        test_image = test_image[:, :, :3]\n",
        "\n",
        "    # Calculate PSNR\n",
        "    psnr_value = metrics.peak_signal_noise_ratio(gt_image, test_image)\n",
        "    return psnr_value"
      ],
      "metadata": {
        "id": "CgwOvNCx1Zb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Calculate SSIM"
      ],
      "metadata": {
        "id": "2nBwedhW1jbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_ssim(gt_path, test_path):\n",
        "    \"\"\"\n",
        "    Calculate SSIM between two images. Assumes both images have same dimensions.\n",
        "    \"\"\"\n",
        "    # Read images\n",
        "    gt_image = io.imread(gt_path)\n",
        "    test_image = io.imread(test_path)\n",
        "\n",
        "    # Remove alpha channel if present\n",
        "    if gt_image.shape[2] == 4:\n",
        "        gt_image = gt_image[:, :, :3]\n",
        "    if test_image.shape[2] == 4:\n",
        "        test_image = test_image[:, :, :3]\n",
        "\n",
        "    # Calculate SSIM (1 = perfect match)\n",
        "    # Axis = 2 because Numpy stores rgb image in 3D array as\n",
        "    # image.shape = (height, width, channels)\n",
        "    # Axis=2 means use last index --> channels\n",
        "    ssim_value = metrics.structural_similarity(gt_image, test_image,\n",
        "                                               channel_axis=2,\n",
        "                                               data_range=255)\n",
        "    return ssim_value"
      ],
      "metadata": {
        "id": "64UoPY3m1iYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Calculate NIQE"
      ],
      "metadata": {
        "id": "jx53S7Hu12Zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def niqe_from_path(image_path, crop_border=0):\n",
        "    \"\"\"\n",
        "    Calculate NIQE for a single image using BasicSR in grayscale\n",
        "    with consistent scaling for better alignment with perception.\n",
        "    \"\"\"\n",
        "    # Open and convert to grayscale\n",
        "    img = Image.open(image_path).convert('L')  # L = grayscale\n",
        "    img_np = np.array(img).astype(np.float32)\n",
        "\n",
        "    # Ensure image is scaled 0-255 as PIL and Skimage convert to 0-1 float format\n",
        "    if img_np.max() <= 1.0:\n",
        "        img_np *= 255.0\n",
        "\n",
        "    # Add channel dimension: HWC Height x Width x Channels\n",
        "    # NIQE from basicsr expects Channel to be last\n",
        "    img_np = img_np[:, :, np.newaxis]\n",
        "\n",
        "    # Calculate NIQE\n",
        "    return bs_calculate_niqe(img_np, crop_border=crop_border, input_order='HWC')\n"
      ],
      "metadata": {
        "id": "chMY2MBV149X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5 get metrics for images inferred from fine-tuned and non-fine tuned model"
      ],
      "metadata": {
        "id": "VYAFHFfG2h2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths for ground truth and inferred images\n",
        "gt_zip = \"/content/drive/MyDrive/Final_project/gt_test_images.zip\"\n",
        "models_zip = \"/content/drive/MyDrive/Final_project/models_test_results.zip\"\n",
        "\n",
        "gt_dir = \"/content/models_test_results/\"\n",
        "models_dir = \"/content/models_test_results/\"\n",
        "\n",
        "# Unzip ground truth\n",
        "with zipfile.ZipFile(gt_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(gt_dir)\n",
        "\n",
        "# unzip model results\n",
        "with zipfile.ZipFile(models_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(models_dir)"
      ],
      "metadata": {
        "id": "ZCyv9SZ_jUcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose model and metric\n",
        "option = input(\"Enter 1 for Real-ESRGAN, 2 for HAT, 3 for SwinIR and 4 for BSRGAN: \")\n",
        "\n",
        "if option == \"1\":\n",
        "    model_name = \"realesrgan\"\n",
        "elif option == \"2\":\n",
        "    model_name = \"hat\"\n",
        "elif option == \"3\":\n",
        "    model_name = \"swinir\"\n",
        "elif option == \"4\":\n",
        "    model_name = \"bsrgan\"\n",
        "else:\n",
        "    raise ValueError(\"Invalid option. Please choose 1, 2, 3, or 4.\")\n",
        "\n",
        "metric_option = input(\"Enter 1 for PSNR, 2 for SSIM, 3 for NIQE: \")\n",
        "metric_name = \"PSNR\" if metric_option == \"1\" else (\"SSIM\" if metric_option == \"2\" else \"NIQE\")\n",
        "\n",
        "# Define folders and versions. versions will later correspond to csv header\n",
        "categories = [\"buildings\", \"desert\", \"snowregion\", \"vegetation\", \"water\"]\n",
        "versions = [\n",
        "    (\"FineTuned\", f\"finetuned_{metric_name.lower()}\"),\n",
        "    (\"NotFineTuned\", f\"non_finetuned_{metric_name.lower()}\")\n",
        "]\n",
        "\n",
        "# Add suffix condition\n",
        "if model_name == \"realesrgan\":\n",
        "    suffix = \"_out.png\"\n",
        "elif model_name == \"hat\":\n",
        "    suffix = \"_HAT-L_SRx4_ImageNet-pretrain.png\"\n",
        "elif model_name == \"swinir\":\n",
        "    suffix = \"_SwinIR.png\"\n",
        "elif model_name == \"bsrgan\":\n",
        "    suffix = \"_BSRGAN.png\"\n",
        "else:\n",
        "    suffix = \".png\"  # fallback\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiNYAAakjY99",
        "outputId": "d49edecb-2abe-49a3-d1e6-b52471d52a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter 1 for Real-ESRGAN, 2 for HAT, 3 for SwinIR and 4 for BSRGAN: 2\n",
            "Enter 1 for PSNR, 2 for SSIM, 3 for NIQE: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "# Loop through categories and versions\n",
        "for folder in categories:\n",
        "    for version_folder, metric_col in versions:\n",
        "        zip_path = os.path.join(models_dir, model_name, version_folder, f\"results_{folder}.zip\")\n",
        "        extract_path = os.path.join(\"/tmp\", f\"{model_name}_{version_folder}_{folder}\")\n",
        "        os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "        if not os.path.exists(zip_path):\n",
        "            print(f\"Zip not found: {zip_path}\")\n",
        "            continue\n",
        "\n",
        "        #unzip categories folder from models_results\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "\n",
        "        for fname in os.listdir(extract_path):\n",
        "            if not fname.endswith(suffix):\n",
        "                continue\n",
        "\n",
        "            inferred_image_path = os.path.join(extract_path, fname)\n",
        "            gt_image_name = fname.replace(suffix, \".png\")\n",
        "            gt_image_path = os.path.join(gt_dir, folder, gt_image_name)\n",
        "\n",
        "            if not os.path.exists(gt_image_path):\n",
        "                print(f\"GT missing for {fname}\")\n",
        "                continue\n",
        "\n",
        "            if metric_option == \"1\":\n",
        "                metric_value = calculate_psnr(gt_image_path, inferred_image_path)\n",
        "            elif metric_option == \"2\":\n",
        "                metric_value = calculate_ssim(gt_image_path, inferred_image_path)\n",
        "            elif metric_option == \"3\":\n",
        "                metric_value = niqe_from_path(inferred_image_path)\n",
        "\n",
        "            entry = next((r for r in results if r[\"image_name\"] == fname), None)\n",
        "            if entry:\n",
        "                entry[metric_col] = metric_value\n",
        "            else:\n",
        "                results.append({\"image_name\": fname, \"category\": folder, metric_col: metric_value})\n",
        "\n",
        "# Save results to CSV\n",
        "df_results = pd.DataFrame(results).fillna(\"\")\n",
        "csv_path = f\"/content/{metric_name.lower()}_{model_name}_results.csv\"\n",
        "df_results.to_csv(csv_path, index=False)\n",
        "print(f\"Saved results to {csv_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l0haHVf2q7C",
        "outputId": "b4788a4c-917c-44c1-9d5c-f3f29aa54acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved results to /content/niqe_hat_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 Get average of metrics"
      ],
      "metadata": {
        "id": "AOE2mLG94hfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!!Important: modify the model_name correct one\n",
        "eval_metrics = [\"psnr\", \"ssim\", \"niqe\"]\n",
        "model_name = \"hat\"\n",
        "\n",
        "for metric in eval_metrics:\n",
        "    csv_path = f\"/content/{metric}_{model_name}_results.csv\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    finetuned_col = f\"finetuned_{metric}\"\n",
        "    non_finetuned_col = f\"non_finetuned_{metric}\"\n",
        "\n",
        "    if finetuned_col in df.columns and non_finetuned_col in df.columns:\n",
        "        avg_df = df.groupby(\"category\")[[finetuned_col, non_finetuned_col]].mean()\n",
        "        print(f\"\\nAverage {metric.upper()} per category for {model_name}:\")\n",
        "        print(avg_df)\n",
        "    else:\n",
        "        print(f\"\\nColumns for metric '{metric}' not found in {csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8wxAccJ4g9s",
        "outputId": "e2552b0a-a5b3-49de-9052-7a09535c8379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average PSNR per category for hat:\n",
            "            finetuned_psnr  non_finetuned_psnr\n",
            "category                                      \n",
            "buildings        13.835934           15.010152\n",
            "desert           17.323169           18.100102\n",
            "snowregion       17.245920           18.631850\n",
            "vegetation       19.520794           19.219196\n",
            "water            20.397658           20.759519\n",
            "\n",
            "Average SSIM per category for hat:\n",
            "            finetuned_ssim  non_finetuned_ssim\n",
            "category                                      \n",
            "buildings         0.309656            0.282576\n",
            "desert            0.347976            0.340328\n",
            "snowregion        0.416024            0.380248\n",
            "vegetation        0.415999            0.338406\n",
            "water             0.664545            0.646071\n",
            "\n",
            "Average NIQE per category for hat:\n",
            "            finetuned_niqe  non_finetuned_niqe\n",
            "category                                      \n",
            "buildings         7.000972            5.813409\n",
            "desert            6.028569            5.650813\n",
            "snowregion        5.821470            5.372560\n",
            "vegetation        6.173843            6.077269\n",
            "water             7.277244            8.497132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 Difference between metrics"
      ],
      "metadata": {
        "id": "hnprnVuU8oCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!!Important: modify the model_name correct one\n",
        "models = [\"realesrgan\"]\n",
        "eval_metrics = [\"psnr\", \"ssim\", \"niqe\"]\n",
        "\n",
        "# Loop over models and eval_metrics\n",
        "for model_name in models:\n",
        "    for metric in eval_metrics:\n",
        "        csv_path = f\"/content/{metric}_{model_name}_results.csv\"\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        # Column names\n",
        "        finetuned_col = f\"finetuned_{metric}\"\n",
        "        non_finetuned_col = f\"non_finetuned_{metric}\"\n",
        "        diff_col = f\"diff_{metric}\"\n",
        "\n",
        "        # Compute difference: positive = fine-tuned better, negative = non-fine-tuned better\n",
        "        if metric == \"niqe\":\n",
        "            df[diff_col] = df[non_finetuned_col] - df[finetuned_col]\n",
        "        else:\n",
        "            df[diff_col] = df[finetuned_col] - df[non_finetuned_col]\n",
        "\n",
        "        # Save updated CSV\n",
        "        df.to_csv(csv_path, index=False)\n",
        "        print(f\"\\nUpdated CSV saved with {diff_col} for {model_name}\")\n",
        "\n",
        "        # Compute 2nd percentile threshold for \"non-finetuned better\" cases\n",
        "        threshold = df[diff_col].quantile(0.02)\n",
        "\n",
        "        # Output worst cases (non-finetuned better)\n",
        "        worst_cases = df[df[diff_col] <= threshold]\n",
        "        print(f\"\\nTop non-finetuned better images for {metric.upper()} - {model_name}:\")\n",
        "        print(worst_cases)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMhWxqEH3t2a",
        "outputId": "a6d1210c-e423-48ee-c5d3-229d2ffcf48b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated CSV saved with diff_psnr for realesrgan\n",
            "\n",
            "Top non-finetuned better images for PSNR - realesrgan:\n",
            "                   image_name category  finetuned_psnr  non_finetuned_psnr  \\\n",
            "62    desert2_patch_6_out.png   desert       13.598085           15.047684   \n",
            "63   desert2_patch_23_out.png   desert       15.215955           16.674884   \n",
            "74   desert2_patch_26_out.png   desert       15.733445           17.372210   \n",
            "91   desert2_patch_22_out.png   desert       16.490226           18.084324   \n",
            "99   desert2_patch_12_out.png   desert       13.795557           15.659758   \n",
            "102   desert2_patch_5_out.png   desert       12.647449           14.579856   \n",
            "\n",
            "     diff_psnr  \n",
            "62   -1.449600  \n",
            "63   -1.458929  \n",
            "74   -1.638765  \n",
            "91   -1.594098  \n",
            "99   -1.864202  \n",
            "102  -1.932407  \n",
            "\n",
            "Updated CSV saved with diff_ssim for realesrgan\n",
            "\n",
            "Top non-finetuned better images for SSIM - realesrgan:\n",
            "                   image_name category  finetuned_ssim  non_finetuned_ssim  \\\n",
            "61   desert2_patch_19_out.png   desert        0.371137            0.407393   \n",
            "62    desert2_patch_6_out.png   desert        0.296858            0.327340   \n",
            "63   desert2_patch_23_out.png   desert        0.327610            0.365937   \n",
            "70   desert2_patch_21_out.png   desert        0.371669            0.412367   \n",
            "91   desert2_patch_22_out.png   desert        0.440759            0.470533   \n",
            "102   desert2_patch_5_out.png   desert        0.274519            0.305194   \n",
            "\n",
            "     diff_ssim  \n",
            "61   -0.036256  \n",
            "62   -0.030481  \n",
            "63   -0.038327  \n",
            "70   -0.040698  \n",
            "91   -0.029775  \n",
            "102  -0.030675  \n",
            "\n",
            "Updated CSV saved with diff_niqe for realesrgan\n",
            "\n",
            "Top non-finetuned better images for NIQE - realesrgan:\n",
            "                       image_name    category  finetuned_niqe  \\\n",
            "40    buildings2_patch_10_out.png   buildings        5.874101   \n",
            "43    buildings2_patch_26_out.png   buildings        6.635609   \n",
            "111   snowregion1_patch_1_out.png  snowregion        7.417335   \n",
            "117  snowregion2_patch_22_out.png  snowregion        5.413569   \n",
            "125   snowregion2_patch_0_out.png  snowregion        6.634453   \n",
            "155   snowregion2_patch_1_out.png  snowregion        6.576936   \n",
            "\n",
            "     non_finetuned_niqe  diff_niqe  \n",
            "40             2.917790  -2.956311  \n",
            "43             3.492887  -3.142721  \n",
            "111            4.181216  -3.236120  \n",
            "117            2.561751  -2.851818  \n",
            "125            3.583949  -3.050504  \n",
            "155            3.182939  -3.393998  \n"
          ]
        }
      ]
    }
  ]
}